import re
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC

# ----------------------------------------------------
# 1. ì„¤ì • ë° ìƒìˆ˜
# ----------------------------------------------------
BASE_URL = "https://korean.visitkorea.or.kr/kfes/list/wntyFstvlList.do"

REGION_DROPDOWN_ID = "searchArea"
DATE_DROPDOWN_ID = "searchDate"
SEOUL_VALUE = "1"
DATE_FILTER_VALUE = ['A','B']  # A: ê°œìµœ ì¤‘, B: ê°œìµœ ì˜ˆì •

# ----------------------------------------------------
# 2. ë‚ ì§œ ì „ì²˜ë¦¬ í•¨ìˆ˜
# ----------------------------------------------------
def preprocess_date(date_string):
    dates = re.findall(r'(\d{4}\.\d{2}\.\d{2})', date_string)
    start_date = dates[0] if len(dates) >= 1 else None
    end_date = dates[-1] if len(dates) >= 1 else None
    return start_date, end_date

# ----------------------------------------------------
# 3. ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ (ë³„ë„ ë“œë¼ì´ë²„)
# ----------------------------------------------------
def crawl_festival_detail(detail_url):
    service = ChromeService(ChromeDriverManager().install())
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    driver = webdriver.Chrome(service=service, options=options)
    wait = WebDriverWait(driver, 10)
    detail_data = {'description': "N/A", 'address': "N/A", 'instagram_url': "N/A"}

    try:
        driver.get(detail_url)
        SELECTORS = {
            'description': "#mainTab > div > div > section.poster_detail > div > div.poster_info_content > div.m_img_fst",
            'address': "#mainTab > div > div > section.poster_detail > div > div.poster_detail_wrap > div > div.img_info_box > ul > li:nth-child(2) > p",
            'instagram_url': "#mainTab > div > div > section.poster_detail > div > div.poster_detail_wrap > div > div.img_info_box > ul > li:nth-child(6) > a"
        }

        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, SELECTORS['description'])))

        try:
            desc = driver.find_element(By.CSS_SELECTOR, SELECTORS['description']).text.strip()
            detail_data['description'] = re.sub(r'\s+', ' ', desc)
        except:
            pass

        try:
            addr = driver.find_element(By.CSS_SELECTOR, SELECTORS['address']).text.strip()
            detail_data['address'] = addr
        except:
            pass

        try:
            insta = driver.find_element(By.CSS_SELECTOR, SELECTORS['instagram_url']).get_attribute('href')
            detail_data['instagram_url'] = insta
        except:
            pass

    except Exception as e:
        print(f"âŒ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
    finally:
        driver.quit()

    return detail_data

# ----------------------------------------------------
# 4. ë©”ì¸ í¬ë¡¤ë§
# ----------------------------------------------------
def get_all_festival_data():
    service = ChromeService(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service)
    wait = WebDriverWait(driver, 15)
    all_results = []

    try:
        driver.get(BASE_URL)
        print("âœ… ê¸°ë³¸ í˜ì´ì§€ ì ‘ì† ì™„ë£Œ")

        # ì§€ì—­ ì„ íƒ (ì„œìš¸)
        wait.until(EC.presence_of_element_located((By.ID, REGION_DROPDOWN_ID)))
        Select(driver.find_element(By.ID, REGION_DROPDOWN_ID)).select_by_value(SEOUL_VALUE)
        time.sleep(1)

        # A(ê°œìµœ ì¤‘), B(ê°œìµœ ì˜ˆì •) ê°ê° ë°˜ë³µ
        for date_filter in DATE_FILTER_VALUE:
            print(f"\nğŸ¯ '{date_filter}' í•„í„° ì ìš© ì¤‘...")

            # ë‚ ì§œ í•„í„° ì„ íƒ
            Select(driver.find_element(By.ID, DATE_DROPDOWN_ID)).select_by_value(date_filter)
            time.sleep(1)

            # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
            search_button = driver.find_element(By.CSS_SELECTOR, "button.btn_search")
            driver.execute_script("arguments[0].click();", search_button)

            # Ajax ë¡œë”© ëŒ€ê¸°
            try:
                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "#fstvlList > li")))
            except:
                print(f"âš ï¸ '{date_filter}' ê²°ê³¼ ì—†ìŒ (ë¦¬ìŠ¤íŠ¸ ë¹„ì–´ ìˆìŒ)")
                continue

            time.sleep(2)
            print(f"âœ… '{date_filter}' í•„í„° ê²°ê³¼ ë¡œë”© ì™„ë£Œ")

            page = 1
            while True:
                print(f"\n===== ğŸ“„ {date_filter} - {page}í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ =====")
                items = driver.find_elements(By.CSS_SELECTOR, "#fstvlList > li")

                if not items:
                    print("ë” ì´ìƒ ì¶•ì œ ì—†ìŒ. ì¢…ë£Œ.")
                    break

                for idx, item in enumerate(items, start=1):
                    try:
                        title = item.find_element(By.CSS_SELECTOR, "a > div.other_festival_content > strong").text.strip()
                        date_raw = item.find_element(By.CSS_SELECTOR, "a > div.other_festival_content > div.date").text
                        start_date, end_date = preprocess_date(date_raw)
                        img_url = item.find_element(By.CSS_SELECTOR, "a > div.other_festival_img > img").get_attribute('src')
                        detail_url = item.find_element(By.CSS_SELECTOR, "a").get_attribute('href')

                        print(f"â–¶ {idx}. {title} ìƒì„¸í˜ì´ì§€ ì´ë™ ì¤‘...")
                        detail_data = crawl_festival_detail(detail_url)

                        result = {
                            'filter': date_filter,
                            'title': title,
                            'image_url': img_url,
                            'start_date': start_date,
                            'end_date': end_date,
                            'detail_url': detail_url,
                            **detail_data
                        }
                        all_results.append(result)
                        print(f"âœ… {title} ì™„ë£Œ")

                    except Exception as e:
                        print(f"âŒ {idx}ë²ˆì§¸ ì¶•ì œ ì˜¤ë¥˜: {e}")

                # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
                try:
                    next_btn = driver.find_element(By.CSS_SELECTOR, "div.paging_wrap a.next")
                    if "disabled" in next_btn.get_attribute("class"):
                        print("ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ. ì¢…ë£Œ.")
                        break
                    driver.execute_script("arguments[0].click();", next_btn)
                    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "#fstvlList > li")))
                    time.sleep(1)
                    page += 1
                except:
                    print("ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì—†ìŒ. ì¢…ë£Œ.")
                    break

    except Exception as e:
        print(f"âŒ ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    finally:
        driver.quit()

    print(f"\nğŸ‰ ì´ {len(all_results)}ê°œ ì¶•ì œ í¬ë¡¤ë§ ì™„ë£Œ")
    return all_results

# ----------------------------------------------------
# 5. ì‹¤í–‰
# ----------------------------------------------------
if __name__ == "__main__":
    data = get_all_festival_data()
    print("\n=== ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ===")
    for i, d in enumerate(data[:3], start=1):
        print(f"{i}. {d['title']} | {d['start_date']}~{d['end_date']}")
        print(f"ì£¼ì†Œ: {d['address']}")
        print(f"ì„¤ëª…: {d['description']}")
