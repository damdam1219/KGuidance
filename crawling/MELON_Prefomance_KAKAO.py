import time
import re
import pandas as pd
import mysql.connector
import requests # ì¹´ì¹´ì˜¤ API í˜¸ì¶œìš©
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from mysql.connector import errorcode

# ----------------------------------------------------
# 1. DB ì„¤ì • ë° í¬ë¡¤ë§ ì„¤ì •
# ----------------------------------------------------

# !!! ì‚¬ìš©ì ì •ë³´ë¥¼ ìì‹ ì˜ MySQL ì„¤ì •ì— ë§ê²Œ ë³€ê²½í•˜ì„¸ìš” !!!
DB_CONFIG = {
    'user': 'root',
    'password': '1234',
    'host': 'localhost',
    'database': 'performance'
}
TABLE_NAME = 'MELON_perfor'
URL = "https://tkglobal.melon.com/main/index.htm?langCd=EN"

# ----------------------------------------------------
# !!! ì¹´ì¹´ì˜¤ API ì„¤ì • (REST API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”) !!!
# ----------------------------------------------------
KAKAO_API_KEY = "."
KAKAO_GEOCODE_URL = "https://dapi.kakao.com/v2/local/search/address.json"


# ----------------------------------------------------
# 2. DB ì—°ê²° ë° í…Œì´ë¸” ìƒì„± í•¨ìˆ˜ (ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ ì¶”ê°€)
# ----------------------------------------------------

def setup_database(db_config, table_name):
    """DBì— ì—°ê²°í•˜ê³  í•„ìš”í•œ ë°ì´í„°ë² ì´ìŠ¤ ë° í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        conn = mysql.connector.connect(
            user=db_config['user'],
            password=db_config['password'],
            host=db_config['host']
        )
        cursor = conn.cursor()

        DB_NAME = db_config['database']
        try:
            cursor.execute(f"CREATE DATABASE IF NOT EXISTS {DB_NAME} DEFAULT CHARACTER SET 'utf8mb4'")
            conn.database = DB_NAME
        except mysql.connector.Error as err:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {err}")
            return None, None

        # í…Œì´ë¸” ìƒì„±: latitude(ìœ„ë„), longitude(ê²½ë„) ì»¬ëŸ¼ ì¶”ê°€
        TABLE_SCHEMA = (f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title VARCHAR(255) NOT NULL,
                start_date DATE,
                end_date DATE,
                location VARCHAR(255),
                latitude DECIMAL(10, 8),
                longitude DECIMAL(11, 8),
                genre VARCHAR(100),
                age_limit VARCHAR(50),
                image_url TEXT
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        cursor.execute(TABLE_SCHEMA)
        print(f"âœ… DB ë° í…Œì´ë¸” '{table_name}' ì¤€ë¹„ ì™„ë£Œ.")
        return conn, cursor

    except mysql.connector.Error as err:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {err}")
        return None, None

# ----------------------------------------------------
# 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì§€ì˜¤ì½”ë”© í•¨ìˆ˜
# ----------------------------------------------------

def preprocess_date(date_string):
    """ë‚ ì§œ ë¬¸ìì—´ì„ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ë¡œ ë¶„ë¦¬í•˜ê³  DATE í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    start_date = None
    end_date = None
    dates = re.findall(r'(\d{4}\.\d{2}\.\d{2})', date_string)
    
    if len(dates) >= 1:
        start_date = dates[0].replace('.', '-')
        end_date = dates[0].replace('.', '-')
        if len(dates) == 2:
            end_date = dates[1].replace('.', '-')
            
    return start_date, end_date

def geocode_location_kakao(location_name):
    """ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ì´ë¦„ì„ ìœ„ë„(lat)ì™€ ê²½ë„(lon)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": location_name}
    
    try:
        response = requests.get(KAKAO_GEOCODE_URL, headers=headers, params=params)
        response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ
        
        data = response.json()
        
        if data['documents']:
            # ê°€ì¥ ì •í™•í•œ ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ì‚¬ìš©
            doc = data['documents'][0]
            # ì¹´ì¹´ì˜¤ APIëŠ” ê²½ë„(X)ì™€ ìœ„ë„(Y) ìˆœì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
            longitude = float(doc['x']) # ê²½ë„
            latitude = float(doc['y'])  # ìœ„ë„
            return latitude, longitude
        else:
            print(f"  âš ï¸ ì§€ì˜¤ì½”ë”© ê²°ê³¼ ì—†ìŒ: {location_name}")
            return None, None
            
    except requests.exceptions.HTTPError as http_err:
        print(f"  âŒ ì¹´ì¹´ì˜¤ API HTTP ì˜¤ë¥˜ ë°œìƒ (í‚¤ ë˜ëŠ” ìš”ì²­ ë¬¸ì œ): {http_err}")
        return None, None
    except Exception as e:
        print(f"  âŒ ì¹´ì¹´ì˜¤ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None, None

# ----------------------------------------------------
# 4. ë©”ì¸ í¬ë¡¤ë§ ë° ì ì¬ ë¡œì§
# ----------------------------------------------------

def run_crawler_and_load_db():
    conn, cursor = setup_database(DB_CONFIG, TABLE_NAME)
    if not conn:
        return

    try:
        service = ChromeService(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service)
        driver.get(URL)
        
        wait = WebDriverWait(driver, 15)
        list_selector = "#conts > div > div:nth-child(1) > ul > li"
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, list_selector)))

        performance_list = driver.find_elements(By.CSS_SELECTOR, list_selector)
        print(f"\nì´ {len(performance_list)}ê°œì˜ ê³µì—° í•­ëª© ë°œê²¬.")

        for i, item in enumerate(performance_list):
            base_selector = f"#conts > div > div:nth-child(1) > ul > li:nth-child({i+1})"
            
            try:
                # 1. í¬ë¡¤ë§ ë°ì´í„° ì¶”ì¶œ
                image_url = driver.find_element(By.CSS_SELECTOR, f"{base_selector} > div.thumb_180x254 > img").get_attribute('src')
                title = driver.find_element(By.CSS_SELECTOR, f"{base_selector} > div.article > h2").text
                date_raw = driver.find_element(By.CSS_SELECTOR, f"{base_selector} > div.article > dl > dd:nth-child(2)").text
                location = driver.find_element(By.CSS_SELECTOR, f"{base_selector} > div.article > dl > dd:nth-child(4)").text
                genre = driver.find_element(By.CSS_SELECTOR, f"{base_selector} > div.article > dl > dd:nth-child(6)").text
                age_limit = driver.find_element(By.CSS_SELECTOR, f"{base_selector} > div.article > dl > dd:nth-child(8)").text

                # 2. ë°ì´í„° ì „ì²˜ë¦¬ (ë‚ ì§œ)
                start_date, end_date = preprocess_date(date_raw)
                if not start_date: continue

                # 3. ì§€ì˜¤ì½”ë”© ì‹¤í–‰ (ìœ„ë„, ê²½ë„ íšë“)
                latitude, longitude = geocode_location_kakao(location)
                
                # 4. DB ì ì¬
                insert_query = f"""
                    INSERT INTO {TABLE_NAME} 
                    (title, start_date, end_date, location, latitude, longitude, genre, age_limit, image_url)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                data = (title, start_date, end_date, location, latitude, longitude, genre, age_limit, image_url)
                
                cursor.execute(insert_query, data)
                print(f"  âœ… {i+1}ë²ˆì§¸ ê³µì—° ì ì¬ ì™„ë£Œ: {title}")

            except Exception as item_e:
                print(f"  âŒ {i+1}ë²ˆì§¸ í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. (ì˜¤ë¥˜: {item_e})")
                continue

        conn.commit()
        print("\nğŸ‰ ëª¨ë“  ë°ì´í„° DBì— ìµœì¢… ì»¤ë°‹ ì™„ë£Œ.")

    except Exception as e:
        print(f"\nğŸ›‘ ë©”ì¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        if 'driver' in locals(): driver.quit()
        if conn and conn.is_connected():
            cursor.close()
            conn.close()
            print("DB ì—°ê²° ì¢…ë£Œ.")

if __name__ == "__main__":
    run_crawler_and_load_db()