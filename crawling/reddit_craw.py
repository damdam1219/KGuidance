import praw
import os
import csv
from dotenv import load_dotenv

# ----------------------------
# 1ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ----------------------------
load_dotenv()

reddit = praw.Reddit(
    client_id=os.getenv("CLIENT_ID"),
    client_secret=os.getenv("CLIENT_SECRET"),
    user_agent=os.getenv("USER_AGENT"),
    username=os.getenv("REDDIT_USERNAME"),
    password=os.getenv("REDDIT_PASSWORD")
)

BASE_URL = "https://www.reddit.com"
SEARCH_QUERY = "korea travel OR korea trip OR seoul travel OR korea travel tips"
TARGET_SUBREDDIT = "KoreaTravel"

# ----------------------------
# 2ï¸âƒ£ Reddit í¬ë¡¤ë§ í•¨ìˆ˜
# ----------------------------
def scrape_reddit_with_praw():
    try:
        print(f"âœ… Reddit ë¡œê·¸ì¸ ì„±ê³µ! í˜„ì¬ ì‚¬ìš©ì: {reddit.user.me()}")
    except Exception as e:
        print(f"âŒ Reddit ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
        return []

    results = []
    print(f"ğŸ” '{SEARCH_QUERY}' ê²€ìƒ‰ ì‹œì‘...")

    subreddit = reddit.subreddit(TARGET_SUBREDDIT)
    search_results = subreddit.search(
        query=SEARCH_QUERY,
        sort="relevance",
        time_filter="year"
    )

    for idx, submission in enumerate(search_results, 1):
        # ëª¨ë“  ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
        submission.comments.replace_more(limit=None)
        comments_list = [c.body.strip() for c in submission.comments.list()]

        post_data = {
            "title": submission.title,
            "url": f"{BASE_URL}{submission.permalink}",
            "content": submission.selftext or "ë³¸ë¬¸ ì—†ìŒ",
            "comments": comments_list
        }

        results.append(post_data)

        # ê²Œì‹œë¬¼ ë° ëŒ“ê¸€ ìˆ˜ ì‹¤ì‹œê°„ ì¶œë ¥
        print(f"[{idx}] '{submission.title}' ê°€ì ¸ì˜´ | ëŒ“ê¸€ ìˆ˜: {len(comments_list)}")

    print(f"\nğŸ“Œ ì´ ê²Œì‹œë¬¼ ìˆ˜: {len(results)}ê°œ")
    return results

# ----------------------------
# 3ï¸âƒ£ CSV ì €ì¥
# ----------------------------
def save_to_csv(posts, filename="reddit_koreatravel_posts.csv"):
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f, quoting=csv.QUOTE_ALL)  # âœ… ì•ˆì „í•˜ê²Œ ë”°ì˜´í‘œ ì²˜ë¦¬
        writer.writerow(["title", "url", "content", "comments"])  # ëŒ“ê¸€ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ì €ì¥
        for post in posts:
            comments_str = " ||| ".join(post["comments"])  # ëŒ“ê¸€ êµ¬ë¶„ì |||
            writer.writerow([
                post["title"],
                post["url"],
                post["content"],
                comments_str
            ])
    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {filename}")

# ----------------------------
# 4ï¸âƒ£ ë©”ì¸ ì‹¤í–‰
# ----------------------------
if __name__ == "__main__":
    results = scrape_reddit_with_praw()
    save_to_csv(results)
